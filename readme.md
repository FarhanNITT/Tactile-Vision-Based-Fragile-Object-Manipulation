# Tactile-Vision Integrated Robotic Systems for Safe Manipulation of Fragile Objects

The objective of our project is to design and implement an end-to-end simulation framework for a tactile-vision integrated robotic system to facilitate the safe, efficient, and reliable manipulation of fragile objects in high-speed environments, with targeted applications such as egg packaging and depalletizing carbonated drink packages. Vision systems provide 3D object data for spatial understanding and optimal grasp point calculation, while tactile sensors deliver real-time feedback on contact forces, surface texture, and slip detection to ensure safe handling.

We achieve this in three stages : 
1) ***Optimal Grasp Location Identification:*** Implemented an extended active vision system using a dual-camera setup to accurately determine optimal grasp points.
2) ***Real-Time Force Sensing and Feedback:*** Integrated tactile sensors to continuously measure and provide feedback on contact forces during manipulation.
3) ***Grasp State Evaluation and Force Regulation:*** Developed a custom visuo-tactile deep learning model to classify grasp states (sliding, stable, excessive) and ensure safe manipulation through precise force control.

For a quick sneak peak into the project , check [Fragile Object Manipulation](https://sites.google.com/d/1DwfRUCuV9kQBkN8MuHpiC_vy4CJZFPHV/p/1IFF5tA-0-DN_xA5NLlL8h7v2BRH1gqmx/edit)

